[
  {
    "question": "importance of reliable benchmarks in AI",
    "input_tokens": 1579,
    "output_tokens": 2927,
    "total_tokens": 4506,
    "input_cost": 7.895e-05,
    "output_cost": 0.0011708,
    "total_cost": 0.00124975,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": true
  },
  {
    "question": "what is evaluation-driven development in ai?",
    "input_tokens": 1410,
    "output_tokens": 2699,
    "total_tokens": 4109,
    "input_cost": 7.05e-05,
    "output_cost": 0.0010796,
    "total_cost": 0.0011501,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": true
  },
  {
    "question": "performance differences in model APIs",
    "input_tokens": 1587,
    "output_tokens": 2418,
    "total_tokens": 4005,
    "input_cost": 7.935e-05,
    "output_cost": 0.0009672,
    "total_cost": 0.00104655,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": true
  },
  {
    "question": "why do OpenAI models seem worse after updates",
    "input_tokens": 1597,
    "output_tokens": 2574,
    "total_tokens": 4171,
    "input_cost": 7.985e-05,
    "output_cost": 0.0010296,
    "total_cost": 0.00110945,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": true
  },
  {
    "question": "Why did Samsung ban ChatGPT?",
    "input_tokens": 1402,
    "output_tokens": 2452,
    "total_tokens": 3854,
    "input_cost": 7.01e-05,
    "output_cost": 0.0009808,
    "total_cost": 0.0010509,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": true
  },
  {
    "question": "methods for decontaminating evaluation data",
    "input_tokens": 1444,
    "output_tokens": 1832,
    "total_tokens": 3276,
    "input_cost": 7.22e-05,
    "output_cost": 0.0007328,
    "total_cost": 0.000805,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": false,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": false
  },
  {
    "question": "best practices for evaluating generative AI responses",
    "input_tokens": 1545,
    "output_tokens": 1835,
    "total_tokens": 3380,
    "input_cost": 7.725e-05,
    "output_cost": 0.000734,
    "total_cost": 0.00081125,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": true
  },
  {
    "question": "limitations of public benchmarks in AI evaluation",
    "input_tokens": 1493,
    "output_tokens": 2260,
    "total_tokens": 3753,
    "input_cost": 7.465e-05,
    "output_cost": 0.000904,
    "total_cost": 0.00097865,
    "answer_relevant": true,
    "completeness": false,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": false
  },
  {
    "question": "evaluating generative AI models",
    "input_tokens": 1593,
    "output_tokens": 2850,
    "total_tokens": 4443,
    "input_cost": 7.965e-05,
    "output_cost": 0.00114,
    "total_cost": 0.00121965,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": true
  },
  {
    "question": "measuring safety and factual consistency in generative models",
    "input_tokens": 1643,
    "output_tokens": 2798,
    "total_tokens": 4441,
    "input_cost": 8.215e-05,
    "output_cost": 0.0011192,
    "total_cost": 0.00120135,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": false
  },
  {
    "question": "How to test AI model's instruction-following ability?",
    "input_tokens": 1730,
    "output_tokens": 2908,
    "total_tokens": 4638,
    "input_cost": 8.65e-05,
    "output_cost": 0.0011632,
    "total_cost": 0.0012497,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": true
  },
  {
    "question": "how to create evaluation sets for AI models",
    "input_tokens": 1555,
    "output_tokens": 1991,
    "total_tokens": 3546,
    "input_cost": 7.775e-05,
    "output_cost": 0.0007964,
    "total_cost": 0.00087415,
    "answer_relevant": true,
    "completeness": false,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": false
  },
  {
    "question": "what benchmarks to use for evaluating LLMs",
    "input_tokens": 1537,
    "output_tokens": 3222,
    "total_tokens": 4759,
    "input_cost": 7.685e-05,
    "output_cost": 0.0012888,
    "total_cost": 0.00136565,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": true
  },
  {
    "question": "correlation scores of AI benchmarks",
    "input_tokens": 1470,
    "output_tokens": 2277,
    "total_tokens": 3747,
    "input_cost": 7.35e-05,
    "output_cost": 0.0009108,
    "total_cost": 0.0009843,
    "answer_relevant": true,
    "completeness": false,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": false
  },
  {
    "question": "AI response length requirements",
    "input_tokens": 1527,
    "output_tokens": 2389,
    "total_tokens": 3916,
    "input_cost": 7.635e-05,
    "output_cost": 0.0009556,
    "total_cost": 0.00103195,
    "answer_relevant": false,
    "completeness": false,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": false,
    "uncertainty_handling": false
  },
  {
    "question": "benchmark selection criteria for AI leaderboards",
    "input_tokens": 1577,
    "output_tokens": 2129,
    "total_tokens": 3706,
    "input_cost": 7.885e-05,
    "output_cost": 0.0008516,
    "total_cost": 0.00093045,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": false,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": false
  },
  {
    "question": "how to create evaluation guidelines for AI systems",
    "input_tokens": 1583,
    "output_tokens": 2540,
    "total_tokens": 4123,
    "input_cost": 7.915e-05,
    "output_cost": 0.001016,
    "total_cost": 0.00109515,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": true
  },
  {
    "question": "evaluating efficiency in AI model performance",
    "input_tokens": 1563,
    "output_tokens": 2026,
    "total_tokens": 3589,
    "input_cost": 7.815e-05,
    "output_cost": 0.0008104,
    "total_cost": 0.00088855,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": false
  },
  {
    "question": "what are open weights in AI models?",
    "input_tokens": 1425,
    "output_tokens": 3233,
    "total_tokens": 4658,
    "input_cost": 7.125e-05,
    "output_cost": 0.0012932,
    "total_cost": 0.00136445,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": false,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": true
  },
  {
    "question": "how to evaluate generated text quality",
    "input_tokens": 1516,
    "output_tokens": 2170,
    "total_tokens": 3686,
    "input_cost": 7.58e-05,
    "output_cost": 0.000868,
    "total_cost": 0.0009438,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": false
  },
  {
    "question": "how to reduce latency when using AI models",
    "input_tokens": 1572,
    "output_tokens": 2770,
    "total_tokens": 4342,
    "input_cost": 7.86e-05,
    "output_cost": 0.001108,
    "total_cost": 0.0011866,
    "answer_relevant": true,
    "completeness": false,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": false
  },
  {
    "question": "why do monopolies harm consumers?",
    "input_tokens": 1396,
    "output_tokens": 3455,
    "total_tokens": 4851,
    "input_cost": 6.98e-05,
    "output_cost": 0.001382,
    "total_cost": 0.0014518,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": false,
    "context_utilization": true,
    "chunk_coverage": false,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": false
  },
  {
    "question": "How does data lineage affect AI model development?",
    "input_tokens": 1566,
    "output_tokens": 1804,
    "total_tokens": 3370,
    "input_cost": 7.83e-05,
    "output_cost": 0.0007216,
    "total_cost": 0.0007999,
    "answer_relevant": true,
    "completeness": false,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": false
  },
  {
    "question": "open source vs proprietary model performance",
    "input_tokens": 1653,
    "output_tokens": 2653,
    "total_tokens": 4306,
    "input_cost": 8.265e-05,
    "output_cost": 0.0010612,
    "total_cost": 0.00114385,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": true
  },
  {
    "question": "techniques for detecting factual inconsistency in language models",
    "input_tokens": 1557,
    "output_tokens": 1930,
    "total_tokens": 3487,
    "input_cost": 7.785e-05,
    "output_cost": 0.000772,
    "total_cost": 0.00084985,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": true
  },
  {
    "question": "What are the implications of a model's data lineage in AI training?",
    "input_tokens": 1560,
    "output_tokens": 2274,
    "total_tokens": 3834,
    "input_cost": 7.8e-05,
    "output_cost": 0.0009096,
    "total_cost": 0.0009876,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": true
  },
  {
    "question": "best practices for reporting model performance",
    "input_tokens": 1517,
    "output_tokens": 2808,
    "total_tokens": 4325,
    "input_cost": 7.585e-05,
    "output_cost": 0.0011232,
    "total_cost": 0.00119905,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": false
  },
  {
    "question": "advanced techniques for evaluating LLMs",
    "input_tokens": 1673,
    "output_tokens": 2799,
    "total_tokens": 4472,
    "input_cost": 8.365e-05,
    "output_cost": 0.0011196,
    "total_cost": 0.00120325,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": true
  },
  {
    "question": "how to evaluate AI applications",
    "input_tokens": 1616,
    "output_tokens": 1513,
    "total_tokens": 3129,
    "input_cost": 8.08e-05,
    "output_cost": 0.0006052,
    "total_cost": 0.000686,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": false
  },
  {
    "question": "mean win rate in model evaluation",
    "input_tokens": 1449,
    "output_tokens": 4202,
    "total_tokens": 5651,
    "input_cost": 7.245e-05,
    "output_cost": 0.0016808,
    "total_cost": 0.00175325,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": true
  },
  {
    "question": "costs of hosting AI models",
    "input_tokens": 1632,
    "output_tokens": 2554,
    "total_tokens": 4186,
    "input_cost": 8.16e-05,
    "output_cost": 0.0010216,
    "total_cost": 0.0011032,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": true
  },
  {
    "question": "best practices for evaluating AI models",
    "input_tokens": 1542,
    "output_tokens": 2062,
    "total_tokens": 3604,
    "input_cost": 7.71e-05,
    "output_cost": 0.0008248,
    "total_cost": 0.0009019,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": true
  },
  {
    "question": "what are essential functionalities for AI models?",
    "input_tokens": 1436,
    "output_tokens": 2517,
    "total_tokens": 3953,
    "input_cost": 7.18e-05,
    "output_cost": 0.0010068,
    "total_cost": 0.0010786,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": true
  },
  {
    "question": "how to rank LLMs based on role performance",
    "input_tokens": 1733,
    "output_tokens": 2799,
    "total_tokens": 4532,
    "input_cost": 8.665e-05,
    "output_cost": 0.0011196,
    "total_cost": 0.00120625,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": false
  },
  {
    "question": "best practices for collecting user feedback on AI performance",
    "input_tokens": 1650,
    "output_tokens": 3232,
    "total_tokens": 4882,
    "input_cost": 8.25e-05,
    "output_cost": 0.0012928,
    "total_cost": 0.0013753,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": false,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": false
  },
  {
    "question": "NLG evaluation metrics examples",
    "input_tokens": 1516,
    "output_tokens": 1660,
    "total_tokens": 3176,
    "input_cost": 7.58e-05,
    "output_cost": 0.000664,
    "total_cost": 0.0007398,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": true
  },
  {
    "question": "open source vs commercial AI models",
    "input_tokens": 1773,
    "output_tokens": 2211,
    "total_tokens": 3984,
    "input_cost": 8.865e-05,
    "output_cost": 0.0008844,
    "total_cost": 0.00097305,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": false
  },
  {
    "question": "evaluating AI with multiple-choice questions",
    "input_tokens": 1581,
    "output_tokens": 2887,
    "total_tokens": 4468,
    "input_cost": 7.905e-05,
    "output_cost": 0.0011548,
    "total_cost": 0.00123385,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": false
  },
  {
    "question": "how to set metrics for chatbot evaluation",
    "input_tokens": 1664,
    "output_tokens": 2639,
    "total_tokens": 4303,
    "input_cost": 8.32e-05,
    "output_cost": 0.0010556,
    "total_cost": 0.0011388,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": false
  },
  {
    "question": "how to detect data contamination in AI models",
    "input_tokens": 1444,
    "output_tokens": 1859,
    "total_tokens": 3303,
    "input_cost": 7.22e-05,
    "output_cost": 0.0007436,
    "total_cost": 0.0008158,
    "answer_relevant": true,
    "completeness": false,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": false
  }
]