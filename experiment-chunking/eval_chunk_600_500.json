[
  {
    "question": "importance of reliable benchmarks in AI",
    "input_tokens": 2238,
    "output_tokens": 3120,
    "total_tokens": 5358,
    "input_cost": 0.0001119,
    "output_cost": 0.001248,
    "total_cost": 0.0013599,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": true
  },
  {
    "question": "what is evaluation-driven development in ai?",
    "input_tokens": 2077,
    "output_tokens": 1792,
    "total_tokens": 3869,
    "input_cost": 0.00010385,
    "output_cost": 0.0007168,
    "total_cost": 0.00082065,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": false
  },
  {
    "question": "performance differences in model APIs",
    "input_tokens": 2330,
    "output_tokens": 2079,
    "total_tokens": 4409,
    "input_cost": 0.0001165,
    "output_cost": 0.0008316,
    "total_cost": 0.0009481,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": true
  },
  {
    "question": "why do OpenAI models seem worse after updates",
    "input_tokens": 2255,
    "output_tokens": 2213,
    "total_tokens": 4468,
    "input_cost": 0.00011275,
    "output_cost": 0.0008852,
    "total_cost": 0.00099795,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": true
  },
  {
    "question": "Why did Samsung ban ChatGPT?",
    "input_tokens": 2094,
    "output_tokens": 2535,
    "total_tokens": 4629,
    "input_cost": 0.0001047,
    "output_cost": 0.001014,
    "total_cost": 0.0011187,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": true
  },
  {
    "question": "methods for decontaminating evaluation data",
    "input_tokens": 2232,
    "output_tokens": 1663,
    "total_tokens": 3895,
    "input_cost": 0.0001116,
    "output_cost": 0.0006652,
    "total_cost": 0.0007768,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": true
  },
  {
    "question": "best practices for evaluating generative AI responses",
    "input_tokens": 2347,
    "output_tokens": 2198,
    "total_tokens": 4545,
    "input_cost": 0.00011735,
    "output_cost": 0.0008792,
    "total_cost": 0.00099655,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": true
  },
  {
    "question": "limitations of public benchmarks in AI evaluation",
    "input_tokens": 2142,
    "output_tokens": 2858,
    "total_tokens": 5000,
    "input_cost": 0.0001071,
    "output_cost": 0.0011432,
    "total_cost": 0.0012503,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": true
  },
  {
    "question": "evaluating generative AI models",
    "input_tokens": 2305,
    "output_tokens": 2608,
    "total_tokens": 4913,
    "input_cost": 0.00011525,
    "output_cost": 0.0010432,
    "total_cost": 0.00115845,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": true
  },
  {
    "question": "measuring safety and factual consistency in generative models",
    "input_tokens": 2431,
    "output_tokens": 2024,
    "total_tokens": 4455,
    "input_cost": 0.00012155,
    "output_cost": 0.0008096,
    "total_cost": 0.00093115,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": false
  },
  {
    "question": "How to test AI model's instruction-following ability?",
    "input_tokens": 2364,
    "output_tokens": 2257,
    "total_tokens": 4621,
    "input_cost": 0.0001182,
    "output_cost": 0.0009028,
    "total_cost": 0.001021,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": true
  },
  {
    "question": "how to create evaluation sets for AI models",
    "input_tokens": 2215,
    "output_tokens": 2950,
    "total_tokens": 5165,
    "input_cost": 0.00011075,
    "output_cost": 0.00118,
    "total_cost": 0.00129075,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": true
  },
  {
    "question": "what benchmarks to use for evaluating LLMs",
    "input_tokens": 2308,
    "output_tokens": 3027,
    "total_tokens": 5335,
    "input_cost": 0.0001154,
    "output_cost": 0.0012108,
    "total_cost": 0.0013262,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": false
  },
  {
    "question": "correlation scores of AI benchmarks",
    "input_tokens": 2160,
    "output_tokens": 4069,
    "total_tokens": 6229,
    "input_cost": 0.000108,
    "output_cost": 0.0016276,
    "total_cost": 0.0017356,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": false
  },
  {
    "question": "AI response length requirements",
    "input_tokens": 2171,
    "output_tokens": 2790,
    "total_tokens": 4961,
    "input_cost": 0.00010855,
    "output_cost": 0.001116,
    "total_cost": 0.00122455,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": false
  },
  {
    "question": "benchmark selection criteria for AI leaderboards",
    "input_tokens": 2213,
    "output_tokens": 2200,
    "total_tokens": 4413,
    "input_cost": 0.00011065,
    "output_cost": 0.00088,
    "total_cost": 0.00099065,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": true
  },
  {
    "question": "how to create evaluation guidelines for AI systems",
    "input_tokens": 2327,
    "output_tokens": 2099,
    "total_tokens": 4426,
    "input_cost": 0.00011635,
    "output_cost": 0.0008396,
    "total_cost": 0.00095595,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": false
  },
  {
    "question": "evaluating efficiency in AI model performance",
    "input_tokens": 2235,
    "output_tokens": 2691,
    "total_tokens": 4926,
    "input_cost": 0.00011175,
    "output_cost": 0.0010764,
    "total_cost": 0.00118815,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": true
  },
  {
    "question": "what are open weights in AI models?",
    "input_tokens": 2136,
    "output_tokens": 2945,
    "total_tokens": 5081,
    "input_cost": 0.0001068,
    "output_cost": 0.001178,
    "total_cost": 0.0012848,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": true
  },
  {
    "question": "how to evaluate generated text quality",
    "input_tokens": 2284,
    "output_tokens": 2027,
    "total_tokens": 4311,
    "input_cost": 0.0001142,
    "output_cost": 0.0008108,
    "total_cost": 0.000925,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": false
  },
  {
    "question": "how to reduce latency when using AI models",
    "input_tokens": 2227,
    "output_tokens": 2146,
    "total_tokens": 4373,
    "input_cost": 0.00011135,
    "output_cost": 0.0008584,
    "total_cost": 0.00096975,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": false
  },
  {
    "question": "why do monopolies harm consumers?",
    "input_tokens": 2096,
    "output_tokens": 3573,
    "total_tokens": 5669,
    "input_cost": 0.0001048,
    "output_cost": 0.0014292,
    "total_cost": 0.001534,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": false,
    "context_utilization": true,
    "chunk_coverage": false,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": false
  },
  {
    "question": "How does data lineage affect AI model development?",
    "input_tokens": 2230,
    "output_tokens": 2254,
    "total_tokens": 4484,
    "input_cost": 0.0001115,
    "output_cost": 0.0009016,
    "total_cost": 0.0010131,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": true
  },
  {
    "question": "open source vs proprietary model performance",
    "input_tokens": 2313,
    "output_tokens": 3102,
    "total_tokens": 5415,
    "input_cost": 0.00011565,
    "output_cost": 0.0012408,
    "total_cost": 0.00135645,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": true
  },
  {
    "question": "techniques for detecting factual inconsistency in language models",
    "input_tokens": 2364,
    "output_tokens": 2320,
    "total_tokens": 4684,
    "input_cost": 0.0001182,
    "output_cost": 0.000928,
    "total_cost": 0.0010462,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": false
  },
  {
    "question": "What are the implications of a model's data lineage in AI training?",
    "input_tokens": 2287,
    "output_tokens": 2237,
    "total_tokens": 4524,
    "input_cost": 0.00011435,
    "output_cost": 0.0008948,
    "total_cost": 0.00100915,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": false
  },
  {
    "question": "best practices for reporting model performance",
    "input_tokens": 2209,
    "output_tokens": 1666,
    "total_tokens": 3875,
    "input_cost": 0.00011045,
    "output_cost": 0.0006664,
    "total_cost": 0.00077685,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": false
  },
  {
    "question": "advanced techniques for evaluating LLMs",
    "input_tokens": 2312,
    "output_tokens": 3500,
    "total_tokens": 5812,
    "input_cost": 0.0001156,
    "output_cost": 0.0014,
    "total_cost": 0.0015156,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": false
  },
  {
    "question": "how to evaluate AI applications",
    "input_tokens": 2326,
    "output_tokens": 2144,
    "total_tokens": 4470,
    "input_cost": 0.0001163,
    "output_cost": 0.0008576,
    "total_cost": 0.0009739,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": false
  },
  {
    "question": "mean win rate in model evaluation",
    "input_tokens": 2197,
    "output_tokens": 1940,
    "total_tokens": 4137,
    "input_cost": 0.00010985,
    "output_cost": 0.000776,
    "total_cost": 0.00088585,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": false,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": false
  },
  {
    "question": "costs of hosting AI models",
    "input_tokens": 2359,
    "output_tokens": 2069,
    "total_tokens": 4428,
    "input_cost": 0.00011795,
    "output_cost": 0.0008276,
    "total_cost": 0.00094555,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": true
  },
  {
    "question": "best practices for evaluating AI models",
    "input_tokens": 2246,
    "output_tokens": 2221,
    "total_tokens": 4467,
    "input_cost": 0.0001123,
    "output_cost": 0.0008884,
    "total_cost": 0.0010007,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": false
  },
  {
    "question": "what are essential functionalities for AI models?",
    "input_tokens": 2140,
    "output_tokens": 2613,
    "total_tokens": 4753,
    "input_cost": 0.000107,
    "output_cost": 0.0010452,
    "total_cost": 0.0011522,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": true
  },
  {
    "question": "how to rank LLMs based on role performance",
    "input_tokens": 2400,
    "output_tokens": 2083,
    "total_tokens": 4483,
    "input_cost": 0.00012,
    "output_cost": 0.0008332,
    "total_cost": 0.0009532,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": true
  },
  {
    "question": "best practices for collecting user feedback on AI performance",
    "input_tokens": 2254,
    "output_tokens": 3286,
    "total_tokens": 5540,
    "input_cost": 0.0001127,
    "output_cost": 0.0013144,
    "total_cost": 0.0014271,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": false,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": false
  },
  {
    "question": "NLG evaluation metrics examples",
    "input_tokens": 2158,
    "output_tokens": 2474,
    "total_tokens": 4632,
    "input_cost": 0.0001079,
    "output_cost": 0.0009896,
    "total_cost": 0.0010975,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": true
  },
  {
    "question": "open source vs commercial AI models",
    "input_tokens": 2346,
    "output_tokens": 3627,
    "total_tokens": 5973,
    "input_cost": 0.0001173,
    "output_cost": 0.0014508,
    "total_cost": 0.0015681,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": false
  },
  {
    "question": "evaluating AI with multiple-choice questions",
    "input_tokens": 2169,
    "output_tokens": 2279,
    "total_tokens": 4448,
    "input_cost": 0.00010845,
    "output_cost": 0.0009116,
    "total_cost": 0.00102005,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": false
  },
  {
    "question": "how to set metrics for chatbot evaluation",
    "input_tokens": 2312,
    "output_tokens": 1655,
    "total_tokens": 3967,
    "input_cost": 0.0001156,
    "output_cost": 0.000662,
    "total_cost": 0.0007776,
    "answer_relevant": true,
    "completeness": true,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": false
  },
  {
    "question": "how to detect data contamination in AI models",
    "input_tokens": 2135,
    "output_tokens": 1481,
    "total_tokens": 3616,
    "input_cost": 0.00010675,
    "output_cost": 0.0005924,
    "total_cost": 0.00069915,
    "answer_relevant": true,
    "completeness": false,
    "grounded_accuracy": true,
    "context_utilization": true,
    "chunk_coverage": true,
    "consistency": true,
    "focused": true,
    "uncertainty_handling": false
  }
]